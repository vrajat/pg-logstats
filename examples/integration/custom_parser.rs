//! Custom parser implementation example
//!
//! This example demonstrates how to create a custom log parser for pg-logstats
//! to handle different PostgreSQL log formats or custom log structures.

use pg_logstats::{LogEntry, LogLevel, PgLogstatsError};
use chrono::{DateTime, Utc};
use regex::Regex;
use std::collections::HashMap;

/// Example custom parser for CSV-format PostgreSQL logs
///
/// This parser handles logs in CSV format which might be generated by
/// PostgreSQL when log_destination = 'csvlog' is configured.
pub struct CsvLogParser {
    // Pre-compiled regex patterns for better performance
    timestamp_regex: Regex,
    level_mapping: HashMap<String, LogLevel>,
}

impl CsvLogParser {
    pub fn new() -> Self {
        let mut level_mapping = HashMap::new();
        level_mapping.insert("DEBUG".to_string(), LogLevel::Debug);
        level_mapping.insert("INFO".to_string(), LogLevel::Info);
        level_mapping.insert("NOTICE".to_string(), LogLevel::Notice);
        level_mapping.insert("WARNING".to_string(), LogLevel::Warning);
        level_mapping.insert("ERROR".to_string(), LogLevel::Error);
        level_mapping.insert("FATAL".to_string(), LogLevel::Fatal);
        level_mapping.insert("PANIC".to_string(), LogLevel::Panic);

        Self {
            timestamp_regex: Regex::new(r"^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3} [A-Z]{3,4}$").unwrap(),
            level_mapping,
        }
    }

    /// Parse a CSV log line
    ///
    /// Expected CSV format:
    /// timestamp,user,database,pid,connection_from,session_id,session_line_num,command_tag,session_start_time,virtual_transaction_id,transaction_id,error_severity,sql_state_code,message,detail,hint,internal_query,internal_query_pos,context,query,query_pos,location,application_name
    pub fn parse_line(&self, line: &str) -> Result<Option<LogEntry>, PgLogstatsError> {
        if line.trim().is_empty() || line.starts_with('#') {
            return Ok(None);
        }

        let fields = self.parse_csv_line(line)?;

        if fields.len() < 14 {
            return Err(PgLogstatsError::Parse(format!("Invalid CSV format: expected at least 14 fields, got {}", fields.len())));
        }

        // Extract fields based on PostgreSQL CSV log format
        let timestamp_str = &fields[0];
        let user = if !fields[1].is_empty() { Some(fields[1].clone()) } else { None };
        let database = if !fields[2].is_empty() { Some(fields[2].clone()) } else { None };
        let connection_id = if !fields[3].is_empty() { Some(fields[3].clone()) } else { None };
        let level_str = &fields[11];
        let message = fields[13].clone();
        let query = if fields.len() > 19 && !fields[19].is_empty() {
            Some(fields[19].clone())
        } else {
            None
        };

        // Parse timestamp
        let timestamp = self.parse_timestamp(timestamp_str)?;

        // Parse log level
        let level = self.level_mapping.get(level_str)
            .cloned()
            .unwrap_or(LogLevel::Info);

        // Extract duration from message if present
        let duration = self.extract_duration(&message);

        Ok(Some(LogEntry {
            timestamp,
            level,
            message,
            query,
            duration,
            connection_id,
            database,
            user,
        }))
    }

    /// Parse CSV line handling quoted fields and escaped quotes
    fn parse_csv_line(&self, line: &str) -> Result<Vec<String>, PgLogstatsError> {
        let mut fields = Vec::new();
        let mut current_field = String::new();
        let mut in_quotes = false;
        let mut chars = line.chars().peekable();

        while let Some(ch) = chars.next() {
            match ch {
                '"' => {
                    if in_quotes {
                        // Check for escaped quote
                        if chars.peek() == Some(&'"') {
                            chars.next(); // consume the second quote
                            current_field.push('"');
                        } else {
                            in_quotes = false;
                        }
                    } else {
                        in_quotes = true;
                    }
                }
                ',' if !in_quotes => {
                    fields.push(current_field.trim().to_string());
                    current_field.clear();
                }
                _ => {
                    current_field.push(ch);
                }
            }
        }

        // Add the last field
        fields.push(current_field.trim().to_string());

        Ok(fields)
    }

    /// Parse timestamp from CSV format
    fn parse_timestamp(&self, timestamp_str: &str) -> Result<DateTime<Utc>, PgLogstatsError> {
        // Handle various timestamp formats
        let formats = [
            "%Y-%m-%d %H:%M:%S%.3f %Z",
            "%Y-%m-%d %H:%M:%S%.3f UTC",
            "%Y-%m-%d %H:%M:%S %Z",
            "%Y-%m-%d %H:%M:%S UTC",
        ];

        for format in &formats {
            if let Ok(dt) = DateTime::parse_from_str(timestamp_str, format) {
                return Ok(dt.with_timezone(&Utc));
            }
        }

        Err(PgLogstatsError::Parse(format!("Unable to parse timestamp: {}", timestamp_str)))
    }

    /// Extract duration from message text
    fn extract_duration(&self, message: &str) -> Option<f64> {
        let duration_regex = Regex::new(r"duration:\s*(\d+(?:\.\d+)?)\s*ms").unwrap();

        if let Some(captures) = duration_regex.captures(message) {
            if let Some(duration_match) = captures.get(1) {
                return duration_match.as_str().parse().ok();
            }
        }

        None
    }
}

/// Example custom parser for JSON-format PostgreSQL logs
pub struct JsonLogParser {
    level_mapping: HashMap<String, LogLevel>,
}

impl JsonLogParser {
    pub fn new() -> Self {
        let mut level_mapping = HashMap::new();
        level_mapping.insert("DEBUG".to_string(), LogLevel::Debug);
        level_mapping.insert("INFO".to_string(), LogLevel::Info);
        level_mapping.insert("NOTICE".to_string(), LogLevel::Notice);
        level_mapping.insert("WARNING".to_string(), LogLevel::Warning);
        level_mapping.insert("ERROR".to_string(), LogLevel::Error);
        level_mapping.insert("FATAL".to_string(), LogLevel::Fatal);
        level_mapping.insert("PANIC".to_string(), LogLevel::Panic);

        Self { level_mapping }
    }

    /// Parse a JSON log line
    pub fn parse_line(&self, line: &str) -> Result<Option<LogEntry>, PgLogstatsError> {
        if line.trim().is_empty() {
            return Ok(None);
        }

        // Parse JSON
        let json_value: serde_json::Value = serde_json::from_str(line)
            .map_err(|e| PgLogstatsError::Parse(format!("Invalid JSON: {}", e)))?;

        let obj = json_value.as_object()
            .ok_or_else(|| PgLogstatsError::Parse("Expected JSON object".to_string()))?;

        // Extract fields
        let timestamp_str = obj.get("timestamp")
            .and_then(|v| v.as_str())
            .ok_or_else(|| PgLogstatsError::Parse("Missing timestamp field".to_string()))?;

        let level_str = obj.get("level")
            .and_then(|v| v.as_str())
            .unwrap_or("INFO");

        let message = obj.get("message")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();

        let query = obj.get("query")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let duration = obj.get("duration_ms")
            .and_then(|v| v.as_f64());

        let user = obj.get("user")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let database = obj.get("database")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        let connection_id = obj.get("connection_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        // Parse timestamp
        let timestamp = DateTime::parse_from_rfc3339(timestamp_str)
            .map_err(|e| PgLogstatsError::Parse(format!("Invalid timestamp: {}", e)))?
            .with_timezone(&Utc);

        // Parse log level
        let level = self.level_mapping.get(level_str)
            .cloned()
            .unwrap_or(LogLevel::Info);

        Ok(Some(LogEntry {
            timestamp,
            level,
            message,
            query,
            duration,
            connection_id,
            database,
            user,
        }))
    }
}

/// Trait for implementing custom parsers
pub trait LogParser {
    fn parse_line(&self, line: &str) -> Result<Option<LogEntry>, PgLogstatsError>;
    fn supports_format(&self, sample: &str) -> bool;
}

impl LogParser for CsvLogParser {
    fn parse_line(&self, line: &str) -> Result<Option<LogEntry>, PgLogstatsError> {
        self.parse_line(line)
    }

    fn supports_format(&self, sample: &str) -> bool {
        // Simple heuristic: check if it looks like CSV with many commas
        let comma_count = sample.matches(',').count();
        comma_count > 10 && !sample.trim_start().starts_with('{')
    }
}

impl LogParser for JsonLogParser {
    fn parse_line(&self, line: &str) -> Result<Option<LogEntry>, PgLogstatsError> {
        self.parse_line(line)
    }

    fn supports_format(&self, sample: &str) -> bool {
        sample.trim_start().starts_with('{') && sample.trim_end().ends_with('}')
    }
}

/// Parser registry for managing multiple parsers
pub struct ParserRegistry {
    parsers: Vec<Box<dyn LogParser>>,
}

impl ParserRegistry {
    pub fn new() -> Self {
        Self {
            parsers: vec![
                Box::new(CsvLogParser::new()),
                Box::new(JsonLogParser::new()),
            ],
        }
    }

    pub fn add_parser(&mut self, parser: Box<dyn LogParser>) {
        self.parsers.push(parser);
    }

    pub fn detect_format(&self, sample_lines: &[&str]) -> Option<&dyn LogParser> {
        let sample = sample_lines.join("\n");

        for parser in &self.parsers {
            if parser.supports_format(&sample) {
                return Some(parser.as_ref());
            }
        }

        None
    }

    pub fn parse_with_best_parser(&self, lines: &[&str]) -> Result<Vec<LogEntry>, PgLogstatsError> {
        let parser = self.detect_format(lines)
            .ok_or_else(|| PgLogstatsError::Parse("No suitable parser found".to_string()))?;

        let mut entries = Vec::new();
        for line in lines {
            if let Some(entry) = parser.parse_line(line)? {
                entries.push(entry);
            }
        }

        Ok(entries)
    }
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("Custom Parser Examples");
    println!("=====================\n");

    // Example 1: CSV Parser
    csv_parser_example()?;

    // Example 2: JSON Parser
    json_parser_example()?;

    // Example 3: Parser Registry
    parser_registry_example()?;

    Ok(())
}

fn csv_parser_example() -> Result<(), Box<dyn std::error::Error>> {
    println!("1. CSV Parser Example");
    println!("--------------------");

    let csv_parser = CsvLogParser::new();

    let csv_lines = vec![
        r#"2024-01-15 10:30:15.123 UTC,postgres,testdb,12345,127.0.0.1:54321,507f1f77bcf86cd799439011,1,SELECT,2024-01-15 10:30:15 UTC,1/0,0,INFO,00000,"statement: SELECT * FROM users WHERE id = 1",,,,,,"SELECT * FROM users WHERE id = 1",0,,psql"#,
        r#"2024-01-15 10:30:15.126 UTC,postgres,testdb,12345,127.0.0.1:54321,507f1f77bcf86cd799439011,2,SELECT,2024-01-15 10:30:15 UTC,1/0,0,INFO,00000,"duration: 0.123 ms",,,,,,,0,,psql"#,
    ];

    for line in csv_lines {
        match csv_parser.parse_line(line)? {
            Some(entry) => {
                println!("Parsed CSV entry:");
                println!("  Timestamp: {}", entry.timestamp);
                println!("  Level: {}", entry.level);
                println!("  User: {:?}", entry.user);
                println!("  Database: {:?}", entry.database);
                println!("  Message: {}", entry.message);
                if let Some(query) = &entry.query {
                    println!("  Query: {}", query);
                }
                if let Some(duration) = entry.duration {
                    println!("  Duration: {}ms", duration);
                }
                println!();
            }
            None => println!("Skipped line"),
        }
    }

    Ok(())
}

fn json_parser_example() -> Result<(), Box<dyn std::error::Error>> {
    println!("2. JSON Parser Example");
    println!("---------------------");

    let json_parser = JsonLogParser::new();

    let json_lines = vec![
        r#"{"timestamp":"2024-01-15T10:30:15.123Z","level":"INFO","message":"statement: SELECT * FROM users WHERE id = 1","query":"SELECT * FROM users WHERE id = 1","user":"postgres","database":"testdb","connection_id":"12345"}"#,
        r#"{"timestamp":"2024-01-15T10:30:15.126Z","level":"INFO","message":"duration: 0.123 ms","duration_ms":0.123,"user":"postgres","database":"testdb","connection_id":"12345"}"#,
        r#"{"timestamp":"2024-01-15T10:30:16.205Z","level":"INFO","message":"statement: INSERT INTO orders (customer_id, total) VALUES (123, 99.99)","query":"INSERT INTO orders (customer_id, total) VALUES (123, 99.99)","user":"app_user","database":"production","connection_id":"12346"}"#,
    ];

    for line in json_lines {
        match json_parser.parse_line(line)? {
            Some(entry) => {
                println!("Parsed JSON entry:");
                println!("  Timestamp: {}", entry.timestamp);
                println!("  Level: {}", entry.level);
                println!("  User: {:?}", entry.user);
                println!("  Database: {:?}", entry.database);
                println!("  Message: {}", entry.message);
                if let Some(query) = &entry.query {
                    println!("  Query: {}", query);
                }
                if let Some(duration) = entry.duration {
                    println!("  Duration: {}ms", duration);
                }
                println!();
            }
            None => println!("Skipped line"),
        }
    }

    Ok(())
}

fn parser_registry_example() -> Result<(), Box<dyn std::error::Error>> {
    println!("3. Parser Registry Example");
    println!("--------------------------");

    let registry = ParserRegistry::new();

    // Test with CSV data
    let csv_sample = vec![
        r#"2024-01-15 10:30:15.123 UTC,postgres,testdb,12345,127.0.0.1:54321,507f1f77bcf86cd799439011,1,SELECT,2024-01-15 10:30:15 UTC,1/0,0,INFO,00000,"statement: SELECT * FROM users WHERE id = 1",,,,,,"SELECT * FROM users WHERE id = 1",0,,psql"#,
    ];

    println!("Detecting format for CSV data...");
    if let Some(parser) = registry.detect_format(&csv_sample) {
        println!("Detected CSV format");
        let entries = registry.parse_with_best_parser(&csv_sample)?;
        println!("Parsed {} entries", entries.len());
    }

    // Test with JSON data
    let json_sample = vec![
        r#"{"timestamp":"2024-01-15T10:30:15.123Z","level":"INFO","message":"statement: SELECT * FROM users WHERE id = 1","query":"SELECT * FROM users WHERE id = 1","user":"postgres","database":"testdb","connection_id":"12345"}"#,
    ];

    println!("\nDetecting format for JSON data...");
    if let Some(_parser) = registry.detect_format(&json_sample) {
        println!("Detected JSON format");
        let entries = registry.parse_with_best_parser(&json_sample)?;
        println!("Parsed {} entries", entries.len());
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_csv_parser() {
        let parser = CsvLogParser::new();
        let line = r#"2024-01-15 10:30:15.123 UTC,postgres,testdb,12345,127.0.0.1:54321,507f1f77bcf86cd799439011,1,SELECT,2024-01-15 10:30:15 UTC,1/0,0,INFO,00000,"statement: SELECT * FROM users WHERE id = 1",,,,,,"SELECT * FROM users WHERE id = 1",0,,psql"#;

        let result = parser.parse_line(line).unwrap();
        assert!(result.is_some());

        let entry = result.unwrap();
        assert_eq!(entry.user, Some("postgres".to_string()));
        assert_eq!(entry.database, Some("testdb".to_string()));
        assert!(entry.query.is_some());
    }

    #[test]
    fn test_json_parser() {
        let parser = JsonLogParser::new();
        let line = r#"{"timestamp":"2024-01-15T10:30:15.123Z","level":"INFO","message":"test message","user":"postgres","database":"testdb"}"#;

        let result = parser.parse_line(line).unwrap();
        assert!(result.is_some());

        let entry = result.unwrap();
        assert_eq!(entry.user, Some("postgres".to_string()));
        assert_eq!(entry.database, Some("testdb".to_string()));
        assert_eq!(entry.level, LogLevel::Info);
    }

    #[test]
    fn test_format_detection() {
        let registry = ParserRegistry::new();

        // Test CSV detection
        let csv_sample = vec![r#"2024-01-15 10:30:15.123 UTC,postgres,testdb,12345,127.0.0.1:54321,507f1f77bcf86cd799439011,1,SELECT,2024-01-15 10:30:15 UTC,1/0,0,INFO,00000,"statement: SELECT * FROM users WHERE id = 1",,,,,,"SELECT * FROM users WHERE id = 1",0,,psql"#];
        assert!(registry.detect_format(&csv_sample).is_some());

        // Test JSON detection
        let json_sample = vec![r#"{"timestamp":"2024-01-15T10:30:15.123Z","level":"INFO","message":"test"}"#];
        assert!(registry.detect_format(&json_sample).is_some());
    }

    #[test]
    fn test_csv_parsing() {
        let parser = CsvLogParser::new();
        let fields = parser.parse_csv_line(r#"field1,"field with spaces","field with ""quotes""",field4"#).unwrap();

        assert_eq!(fields.len(), 4);
        assert_eq!(fields[0], "field1");
        assert_eq!(fields[1], "field with spaces");
        assert_eq!(fields[2], r#"field with "quotes""#);
        assert_eq!(fields[3], "field4");
    }
}
